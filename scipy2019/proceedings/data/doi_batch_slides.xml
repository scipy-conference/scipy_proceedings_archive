<doi_batch xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns="http://www.crossref.org/schema/4.4.2" version="4.4.2" xsi:schemaLocation="http://www.crossref.org/schema/4.4.2 http://www.crossref.org/schemas/crossref4.4.2.xsd">
  <head>
  <doi_batch_id>Majora.7ddc1dd1-16c1d71523c</doi_batch_id>
  <timestamp>1563883661</timestamp>
  <depositor>
  <depositor_name>Dillon Niederhut</depositor_name>
  <email_address>dillon.niederhut@gmail.com</email_address>
  </depositor>
  <registrant>Crossref</registrant>
  </head>
  <body>
  <database>
  <database_metadata language="en">
  <contributors>
  <person_name contributor_role="editor" sequence="first">
  <given_name>Dillon</given_name>
  <surname>Niederhut</surname>
  </person_name>
  </contributors>
  <titles>
  <title>Proceedings of the Python in Science Conference</title>
  </titles>
  </database_metadata>
  <dataset dataset_type="other">
  <contributors>
  <person_name contributor_role="author" sequence="first">
  <given_name>The Tabula</given_name>
  <surname>consortium</surname>
  </person_name>
  <person_name contributor_role="author" sequence="additional">
  <given_name>Angela</given_name>
  <surname>Pisco</surname>
  </person_name>
  <person_name contributor_role="author" sequence="additional">
  <given_name>Nicholas</given_name>
  <surname>Schaum</surname>
  </person_name>
  <person_name contributor_role="author" sequence="additional">
  <given_name>Aaron</given_name>
  <surname>McGeever</surname>
  </person_name>
  <person_name contributor_role="author" sequence="additional">
  <given_name>Jim</given_name>
  <surname>Karkanias</surname>
  </person_name>
  <person_name contributor_role="author" sequence="additional">
  <given_name>Norma</given_name>
  <surname>Neff</surname>
  </person_name>
  <person_name contributor_role="author" sequence="additional">
  <given_name>Spyros</given_name>
  <surname>Darmanis</surname>
  </person_name>
  <person_name contributor_role="author" sequence="additional">
  <given_name>Tony</given_name>
  <surname>Wyss-Coray</surname>
  </person_name>
  <person_name contributor_role="author" sequence="additional">
  <given_name>Stephen</given_name>
  <surname>Quake</surname>
  </person_name>
  </contributors>
  <titles>
  <title>The Mouse Aging Cell Atlas: cell biology meets Python</title>
  </titles>
  <database_date>
  <publication_date>
  <year>2019</year>
  </publication_date>
  </database_date>
  <description>Tabula Muris Senis is a single cell transcriptomic atlas across a mouse's life span that reveals new molecular info on aging. This presentations illustrates how the Python ecosystem makes such a scientific expedition possible.</description>
  <program xmlns="http://www.crossref.org/relations.xsd" name="relations">
  <related_item>
  <inter_work_relation identifier-type="doi" relationship-type="isPartOf">10.25080/issn.2575-9752</inter_work_relation>
  </related_item>
  </program>
  <doi_data>
  <doi>10.25080/Majora-7ddc1dd1-023</doi>
  <resource>https://zenodo.org/record/3346125</resource>
  </doi_data>
  </dataset>
  <dataset dataset_type="other">
  <contributors>
  <person_name contributor_role="author" sequence="first">
  <given_name>David</given_name>
  <surname>Nicholson</surname>
  </person_name>
  </contributors>
  <titles>
  <title>Automated Annotation of Animal Vocalizations</title>
  </titles>
  <database_date>
  <publication_date>
  <year>2019</year>
  </publication_date>
  </database_date>
  <description>lightning talk about automated annotation of vocalizations with neural net TweetyNet and the vak and crowsetta libraries</description>
  <program xmlns="http://www.crossref.org/relations.xsd" name="relations">
  <related_item>
  <inter_work_relation identifier-type="doi" relationship-type="isPartOf">10.25080/issn.2575-9752</inter_work_relation>
  </related_item>
  </program>
  <doi_data>
  <doi>10.25080/Majora-7ddc1dd1-024</doi>
  <resource>https://zenodo.org/record/3346101</resource>
  </doi_data>
  </dataset>
  <dataset dataset_type="other">
  <contributors>
  <person_name contributor_role="author" sequence="first">
  <given_name>Kyle</given_name>
  <surname>Niemeyer</surname>
  </person_name>
  <person_name contributor_role="author" sequence="additional">
  <given_name>Jeffrey</given_name>
  <surname>Carver</surname>
  </person_name>
  <person_name contributor_role="author" sequence="additional">
  <given_name>Karthik</given_name>
  <surname>Ram</surname>
  </person_name>
  </contributors>
  <titles>
  <title>US Research Software Sustainability Institute (URSSI) Pilot 'Summer' School</title>
  </titles>
  <database_date>
  <publication_date>
  <year>2019</year>
  </publication_date>
  </database_date>
  <description>The US Research Software Sustainability Institute (URSSI) is offering a pilot 'summer' school in December 2019, to teach skills and best practices for developing research software. Apply now!</description>
  <program xmlns="http://www.crossref.org/relations.xsd" name="relations">
  <related_item>
  <inter_work_relation identifier-type="doi" relationship-type="isPartOf">10.25080/issn.2575-9752</inter_work_relation>
  </related_item>
  </program>
  <doi_data>
  <doi>10.25080/Majora-7ddc1dd1-025</doi>
  <resource>https://zenodo.org/record/3346096</resource>
  </doi_data>
  </dataset>
  <dataset dataset_type="other">
  <contributors>
  <person_name contributor_role="author" sequence="first">
  <given_name>Matt</given_name>
  <surname>Haberland</surname>
  </person_name>
  </contributors>
  <titles>
  <title>SciPy: not just a conference!</title>
  </titles>
  <database_date>
  <publication_date>
  <year>2019</year>
  </publication_date>
  </database_date>
  <description>Besides a conference, 'SciPy' is also a library that provides fundamental building blocks for modeling and solving scientific problems. SciPy includes algorithms for optimization, interpolation, statistics, fast Fourier transforms, and many other classes of problems; it also provides specialized data structures, such as k-dimensional trees and sparse matrices. This presentation summarizes the current status and future plans of the SciPy library.</description>
  <program xmlns="http://www.crossref.org/relations.xsd" name="relations">
  <related_item>
  <inter_work_relation identifier-type="doi" relationship-type="isPartOf">10.25080/issn.2575-9752</inter_work_relation>
  </related_item>
  </program>
  <doi_data>
  <doi>10.25080/Majora-7ddc1dd1-022</doi>
  <resource>https://zenodo.org/record/3346092</resource>
  </doi_data>
  </dataset>
  <dataset dataset_type="other">
  <contributors>
  <person_name contributor_role="author" sequence="first">
  <given_name>Jackson</given_name>
  <surname>Anderson</surname>
  </person_name>
  <person_name contributor_role="author" sequence="additional">
  <given_name>Dana</given_name>
  <surname>Weinstein</surname>
  </person_name>
  </contributors>
  <titles>
  <title>PyMeasRF: Automating RF Device Measurements Using Python</title>
  </titles>
  <database_date>
  <publication_date>
  <year>2019</year>
  </publication_date>
  </database_date>
  <description>This poster introduces a Test and Measurement (T&amp;M)-related python package that has been written to enable RF-related T&amp;M automation and speed electrical test development time. Presented are two case studies that highlight the ways in which the package has been used at Purdue to increase productivity and enable collecting and visualizing device data at scale. Also provided is an overview of the package structure and a discussion of the challenges faced in developing packages for the T&amp;M ecosystem.</description>
  <program xmlns="http://www.crossref.org/relations.xsd" name="relations">
  <related_item>
  <inter_work_relation identifier-type="doi" relationship-type="isPartOf">10.25080/issn.2575-9752</inter_work_relation>
  </related_item>
  </program>
  <doi_data>
  <doi>10.25080/Majora-7ddc1dd1-014</doi>
  <resource>https://zenodo.org/record/3346201</resource>
  </doi_data>
  </dataset>
  <dataset dataset_type="other">
  <contributors>
  <person_name contributor_role="author" sequence="first">
  <given_name>Gavin</given_name>
  <surname>Wiggins</surname>
  </person_name>
  <person_name contributor_role="author" sequence="additional">
  <given_name>Srikanth</given_name>
  <surname>Allu</surname>
  </person_name>
  <person_name contributor_role="author" sequence="additional">
  <given_name>Hsin</given_name>
  <surname>Wang</surname>
  </person_name>
  </contributors>
  <titles>
  <title>A Pythonic Equivalent Circuit Model for Battery Research</title>
  </titles>
  <database_date>
  <publication_date>
  <year>2019</year>
  </publication_date>
  </database_date>
  <description>Electric vehicles are poised to reduce fuel consumption and carbon emissions around the world. To ensure efficient operation of the battery pack, an effective battery management system must be implemented. Equivalent circuit models utilize a lumped battery modeling approach that relies on a small parameter space. The simplicity of these models offers near real-time results with good enough accuracy for battery management systems. In this presentation, we will discuss the use of several Python packages such as Pandas, NumPy, SciPy, and Matplotlib for creating equivalent circuit models.</description>
  <program xmlns="http://www.crossref.org/relations.xsd" name="relations">
  <related_item>
  <inter_work_relation identifier-type="doi" relationship-type="isPartOf">10.25080/issn.2575-9752</inter_work_relation>
  </related_item>
  </program>
  <doi_data>
  <doi>10.25080/Majora-7ddc1dd1-015</doi>
  <resource>https://zenodo.org/record/3346199</resource>
  </doi_data>
  </dataset>
  <dataset dataset_type="other">
  <contributors>
  <person_name contributor_role="author" sequence="first">
  <given_name>Nadia</given_name>
  <surname>Tahiri</surname>
  </person_name>
  <person_name contributor_role="author" sequence="additional">
  <given_name>Bogdan</given_name>
  <surname>Mazoure</surname>
  </person_name>
  <person_name contributor_role="author" sequence="additional">
  <given_name>Vladimir</given_name>
  <surname>Makarenkov</surname>
  </person_name>
  </contributors>
  <titles>
  <title>An intelligent shopping list based on the application of partitioning and machine learning algorithms</title>
  </titles>
  <database_date>
  <publication_date>
  <year>2019</year>
  </publication_date>
  </database_date>
  <description>A grocery list is an integral part of the shopping experience of many consumers. First, we propose a new machine learning model written in Python 3 that predicts which grocery products the consumer will buy again or will try to buy for the first time, and in which store(s) the purchase will be made. Second, we introduce a smart shopping template to provide consumers with a personalized weekly shopping list based on their shopping history and known preferences. As the explanatory variables, we used available grocery shopping history, weekly product promotion information for a given region, as well as the product price statistics.</description>
  <program xmlns="http://www.crossref.org/relations.xsd" name="relations">
  <related_item>
  <inter_work_relation identifier-type="doi" relationship-type="isPartOf">10.25080/issn.2575-9752</inter_work_relation>
  </related_item>
  </program>
  <doi_data>
  <doi>10.25080/Majora-7ddc1dd1-016</doi>
  <resource>https://zenodo.org/record/3346195</resource>
  </doi_data>
  </dataset>
  <dataset dataset_type="other">
  <contributors>
  <person_name contributor_role="author" sequence="first">
  <given_name>Pi-Yueh</given_name>
  <surname>Chuang</surname>
  </person_name>
  <person_name contributor_role="author" sequence="additional">
  <given_name>Tracy</given_name>
  <surname>Thorleifson</surname>
  </person_name>
  <person_name contributor_role="author" sequence="additional">
  <given_name>Lorena</given_name>
  <surname>Barba</surname>
  </person_name>
  </contributors>
  <titles>
  <title>Python Workflow for High-Fidelity Modeling of Overland Hydrocarbon Flows with GeoClaw and Cloud Computing</title>
  </titles>
  <database_date>
  <publication_date>
  <year>2019</year>
  </publication_date>
  </database_date>
  <description>We expanded GeoClaw, a shallow-water solver, for computing overland hydrocarbon flows, and developed a Python workflow for risk analysis of pipeline ruptures on Microsoft Azure cloud resources. The added functionality in GeoClaw includes rupture-point inflows, evaporation, Darcy-Weisbach friction, and in-land hydrologic features. The Python workflow automates running and controlling simulations on Azure clusters. The goal is performing analysis on hundreds or thousands of potential rupture points along a pipeline. We also developed a Python toolbox that integrates GeoClaw and the Azure workflow with ArcGIS Pro, and an equivalent Jupyter-based workflow, while Jupyter notebooks also serve as automatic reports.</description>
  <program xmlns="http://www.crossref.org/relations.xsd" name="relations">
  <related_item>
  <inter_work_relation identifier-type="doi" relationship-type="isPartOf">10.25080/issn.2575-9752</inter_work_relation>
  </related_item>
  </program>
  <doi_data>
  <doi>10.25080/Majora-7ddc1dd1-017</doi>
  <resource>https://zenodo.org/record/3346190</resource>
  </doi_data>
  </dataset>
  <dataset dataset_type="other">
  <contributors>
  <person_name contributor_role="author" sequence="first">
  <given_name>Henry</given_name>
  <surname>Senyondo</surname>
  </person_name>
  <person_name contributor_role="author" sequence="additional">
  <given_name>Andrew</given_name>
  <surname>Zhang</surname>
  </person_name>
  <person_name contributor_role="author" sequence="additional">
  <given_name>Ethan</given_name>
  <surname>White</surname>
  </person_name>
  </contributors>
  <titles>
  <title>The PyDataWeaver: A data integration platform</title>
  </titles>
  <database_date>
  <publication_date>
  <year>2019</year>
  </publication_date>
  </database_date>
  <description>Combine publicly available data into ready-to-analyze datasets. Most research questions require integrating multiple datasets. Researchers typically have to manually create these combined datasets using databases, programming languages and GIS systems. The PyDataWeaver automates the task of integrating multiple data sources to create new comprehensive datasets using JSON based a data integration standard.</description>
  <program xmlns="http://www.crossref.org/relations.xsd" name="relations">
  <related_item>
  <inter_work_relation identifier-type="doi" relationship-type="isPartOf">10.25080/issn.2575-9752</inter_work_relation>
  </related_item>
  </program>
  <doi_data>
  <doi>10.25080/Majora-7ddc1dd1-018</doi>
  <resource>https://zenodo.org/record/3346188</resource>
  </doi_data>
  </dataset>
  <dataset dataset_type="other">
  <contributors>
  <person_name contributor_role="author" sequence="first">
  <given_name>Matthew</given_name>
  <surname>Feickert</surname>
  </person_name>
  <person_name contributor_role="author" sequence="additional">
  <given_name>Lukas</given_name>
  <surname>Heinrich</surname>
  </person_name>
  <person_name contributor_role="author" sequence="additional">
  <given_name>Giordon</given_name>
  <surname>Stark</surname>
  </person_name>
  <person_name contributor_role="author" sequence="additional">
  <given_name>Kyle</given_name>
  <surname>Cranmer</surname>
  </person_name>
  </contributors>
  <titles>
  <title>pyhf: a pure Python statistical fitting library for High Energy Physics with tensors and autograd</title>
  </titles>
  <database_date>
  <publication_date>
  <year>2019</year>
  </publication_date>
  </database_date>
  <description>In experimental high energy physics, the common HistFactory p.d.f. template and fitting tools have only existed within the C++ based ROOT framework developed and maintained by CERN. pyhf is a pure-Python implementation of that statistical model for multi-bin histogram-based analysis with interval estimation based on 'Asymptotic formulae for likelihood-based tests of new physics' [arxiv:1007.1727]. pyhf supports modern computational graph libraries such as TensorFlow and PyTorch as computational backends in order to make use of features such as auto-differentiation and GPU acceleration and defines models with an expressive JSON schema.</description>
  <program xmlns="http://www.crossref.org/relations.xsd" name="relations">
  <related_item>
  <inter_work_relation identifier-type="doi" relationship-type="isPartOf">10.25080/issn.2575-9752</inter_work_relation>
  </related_item>
  </program>
  <doi_data>
  <doi>10.25080/Majora-7ddc1dd1-019</doi>
  <resource>https://zenodo.org/record/3346186</resource>
  </doi_data>
  </dataset>
  <dataset dataset_type="other">
  <contributors>
  <person_name contributor_role="author" sequence="first">
  <given_name>Gavin</given_name>
  <surname>Wiggins</surname>
  </person_name>
  </contributors>
  <titles>
  <title>Using Python to Model Biomass Pyrolysis Reactors</title>
  </titles>
  <database_date>
  <publication_date>
  <year>2019</year>
  </publication_date>
  </database_date>
  <description>Fast pyrolysis is a leading candidate technology for the thermochemical conversion of solid biomass into liquid bio-oil which can be used for biofuel and high-value chemical production. Bio-oil is commonly generated in fluidized, circulating, or entrained flow reactor systems where optimal reactor design and control are crucial to achieving commercially viable products. In this presentation, we will discuss the use of several Python packages such as Pandas, NumPy, SciPy, Matplotlib, and Chemics for creating reactor models for biomass fast pyrolysis research.</description>
  <program xmlns="http://www.crossref.org/relations.xsd" name="relations">
  <related_item>
  <inter_work_relation identifier-type="doi" relationship-type="isPartOf">10.25080/issn.2575-9752</inter_work_relation>
  </related_item>
  </program>
  <doi_data>
  <doi>10.25080/Majora-7ddc1dd1-01a</doi>
  <resource>https://zenodo.org/record/3346184</resource>
  </doi_data>
  </dataset>
  <dataset dataset_type="other">
  <contributors>
  <person_name contributor_role="author" sequence="first">
  <given_name>David</given_name>
  <surname>Hagen</surname>
  </person_name>
  <person_name contributor_role="author" sequence="additional">
  <given_name>Nikolay</given_name>
  <surname>Mayorov</surname>
  </person_name>
  </contributors>
  <titles>
  <title>Class-based ODE solvers and event detection in SciPy</title>
  </titles>
  <database_date>
  <publication_date>
  <year>2019</year>
  </publication_date>
  </database_date>
  <description>In SciPy 1.0, a new interface for solving ODE initial value problems was added to scipy.integrate. The solve_ivp function and OdeSolver base class provide additional features and greater extensibility over the previous odeint function and ode base class.</description>
  <program xmlns="http://www.crossref.org/relations.xsd" name="relations">
  <related_item>
  <inter_work_relation identifier-type="doi" relationship-type="isPartOf">10.25080/issn.2575-9752</inter_work_relation>
  </related_item>
  </program>
  <doi_data>
  <doi>10.25080/Majora-7ddc1dd1-01b</doi>
  <resource>https://zenodo.org/record/3346180</resource>
  </doi_data>
  </dataset>
  <dataset dataset_type="other">
  <contributors>
  <person_name contributor_role="author" sequence="first">
  <given_name>Peter</given_name>
  <surname>Kerpedjiev</surname>
  </person_name>
  <person_name contributor_role="author" sequence="additional">
  <given_name>Nezar</given_name>
  <surname>Abdennur</surname>
  </person_name>
  <person_name contributor_role="author" sequence="additional">
  <given_name>Fritz</given_name>
  <surname>Lekschas</surname>
  </person_name>
  </contributors>
  <titles>
  <title>To a Billion and Beyond: How to Visually Explore, Compare and Share Large Quantitative Datasets with HiGlass</title>
  </titles>
  <database_date>
  <publication_date>
  <year>2019</year>
  </publication_date>
  </database_date>
  <description>We describe how HiGlass tackles the challenges associated with collaborative visual exploration of multiscale scientific data.</description>
  <program xmlns="http://www.crossref.org/relations.xsd" name="relations">
  <related_item>
  <inter_work_relation identifier-type="doi" relationship-type="isPartOf">10.25080/issn.2575-9752</inter_work_relation>
  </related_item>
  </program>
  <doi_data>
  <doi>10.25080/Majora-7ddc1dd1-01c</doi>
  <resource>https://zenodo.org/record/3346228</resource>
  </doi_data>
  </dataset>
  <dataset dataset_type="other">
  <contributors>
  <person_name contributor_role="author" sequence="first">
  <given_name>Ralf</given_name>
  <surname>Gommers</surname>
  </person_name>
  <person_name contributor_role="author" sequence="additional">
  <given_name>Sebastian</given_name>
  <surname>Berg</surname>
  </person_name>
  <person_name contributor_role="author" sequence="additional">
  <given_name>Matti</given_name>
  <surname>Picus</surname>
  </person_name>
  <person_name contributor_role="author" sequence="additional">
  <given_name>Tyler</given_name>
  <surname>Reddy</surname>
  </person_name>
  <person_name contributor_role="author" sequence="additional">
  <given_name>St√©fan</given_name>
  <surname>van der Walt</surname>
  </person_name>
  <person_name contributor_role="author" sequence="additional">
  <given_name>Charles</given_name>
  <surname>Harris</surname>
  </person_name>
  </contributors>
  <titles>
  <title>Inside NumPy: Preparing for the next decade</title>
  </titles>
  <database_date>
  <publication_date>
  <year>2019</year>
  </publication_date>
  </database_date>
  <description>Over the past year, and for the first time since its creation, NumPy has been operating with dedicated funding. NumPy developers think it has invigorated the project and its community. But is that true, and how can we know? We will give an overview of the actions we've taken, both successful and unsuccessful, to improve sustainability of the NumPy project and its community. We will draw some lessons from a first year of grant-funded activity, discuss key obstacles faced, attempt to quantify what we need to operate sustainably, and present a vision for the project and how we plan to realize it.</description>
  <program xmlns="http://www.crossref.org/relations.xsd" name="relations">
  <related_item>
  <inter_work_relation identifier-type="doi" relationship-type="isPartOf">10.25080/issn.2575-9752</inter_work_relation>
  </related_item>
  </program>
  <doi_data>
  <doi>10.25080/Majora-7ddc1dd1-01d</doi>
  <resource>https://zenodo.org/record/3346222</resource>
  </doi_data>
  </dataset>
  <dataset dataset_type="other">
  <contributors>
  <person_name contributor_role="author" sequence="first">
  <given_name>Anderson</given_name>
  <surname>Banihirwe</surname>
  </person_name>
  <person_name contributor_role="author" sequence="additional">
  <given_name>Matthew</given_name>
  <surname>Rocklin</surname>
  </person_name>
  <person_name contributor_role="author" sequence="additional">
  <given_name>Joseph</given_name>
  <surname>Hamman</surname>
  </person_name>
  <person_name contributor_role="author" sequence="additional">
  <given_name>Julia</given_name>
  <surname>Kent</surname>
  </person_name>
  <person_name contributor_role="author" sequence="additional">
  <given_name>Kevin</given_name>
  <surname>Paul</surname>
  </person_name>
  </contributors>
  <titles>
  <title>Turning HPC Systems into Interactive Data Analysis Platforms using Jupyter and Dask</title>
  </titles>
  <database_date>
  <publication_date>
  <year>2019</year>
  </publication_date>
  </database_date>
  <description>This talk demonstrates how to use Dask and Jupyter on large high-performance computing (HPC) systems to scale and accelerate large interactive data analysis tasks -- effectively turning HPC systems into interactive big-data platforms. We will introduce dask-jobqueue which allows users to seamlessly deploy and scale dask on HPC clusters that use a variety of job queuing systems such as PBS, Slurm, SGE, and LSF. We will also introduce dask-mpi, a Python package that makes deploying Dask easy from within a distributed MPI environment.</description>
  <program xmlns="http://www.crossref.org/relations.xsd" name="relations">
  <related_item>
  <inter_work_relation identifier-type="doi" relationship-type="isPartOf">10.25080/issn.2575-9752</inter_work_relation>
  </related_item>
  </program>
  <doi_data>
  <doi>10.25080/Majora-7ddc1dd1-01e</doi>
  <resource>https://zenodo.org/record/3346217</resource>
  </doi_data>
  </dataset>
  <dataset dataset_type="other">
  <contributors>
  <person_name contributor_role="author" sequence="first">
  <given_name>Shammamah</given_name>
  <surname>Hossain</surname>
  </person_name>
  </contributors>
  <titles>
  <title>Visualization of Bioinformatics Data with Dash Bio</title>
  </titles>
  <database_date>
  <publication_date>
  <year>2019</year>
  </publication_date>
  </database_date>
  <description>Dash Bio is a suite of bioinformatics components designed to work with Plotly's Dash. This talk contains information about Plotly and Dash, a subset of the Dash Bio components, and a small section related to the dash-bio-utils library, which contains a set of parsing scripts for popular bioinformatics databases.</description>
  <program xmlns="http://www.crossref.org/relations.xsd" name="relations">
  <related_item>
  <inter_work_relation identifier-type="doi" relationship-type="isPartOf">10.25080/issn.2575-9752</inter_work_relation>
  </related_item>
  </program>
  <doi_data>
  <doi>10.25080/Majora-7ddc1dd1-01f</doi>
  <resource>https://zenodo.org/record/3346213</resource>
  </doi_data>
  </dataset>
  <dataset dataset_type="other">
  <contributors>
  <person_name contributor_role="author" sequence="first">
  <given_name>Laurie</given_name>
  <surname>Stephey</surname>
  </person_name>
  <person_name contributor_role="author" sequence="additional">
  <given_name>Rollin</given_name>
  <surname>Thomas</surname>
  </person_name>
  <person_name contributor_role="author" sequence="additional">
  <given_name>Stephen</given_name>
  <surname>Bailey</surname>
  </person_name>
  </contributors>
  <titles>
  <title>Optimizing Python-Based Spectroscopic Data Processing on NERSC Supercomputers</title>
  </titles>
  <database_date>
  <publication_date>
  <year>2019</year>
  </publication_date>
  </database_date>
  <description>A case study in profiling and optimizing an image processing application for NERSC supercomputer systems</description>
  <program xmlns="http://www.crossref.org/relations.xsd" name="relations">
  <related_item>
  <inter_work_relation identifier-type="doi" relationship-type="isPartOf">10.25080/issn.2575-9752</inter_work_relation>
  </related_item>
  </program>
  <doi_data>
  <doi>10.25080/Majora-7ddc1dd1-020</doi>
  <resource>https://zenodo.org/record/3346209</resource>
  </doi_data>
  </dataset>
  <dataset dataset_type="other">
  <contributors>
  <person_name contributor_role="author" sequence="first">
  <given_name>David</given_name>
  <surname>Nicholson</surname>
  </person_name>
  </contributors>
  <titles>
  <title>Building and Replicating Models of Visual Search Behavior with Tensorflow and the Scientific Python Stack</title>
  </titles>
  <database_date>
  <publication_date>
  <year>2019</year>
  </publication_date>
  </database_date>
  <description>A presentation about using open-source software to replicate and build models of how the brain performs visual search tasks</description>
  <program xmlns="http://www.crossref.org/relations.xsd" name="relations">
  <related_item>
  <inter_work_relation identifier-type="doi" relationship-type="isPartOf">10.25080/issn.2575-9752</inter_work_relation>
  </related_item>
  </program>
  <doi_data>
  <doi>10.25080/Majora-7ddc1dd1-021</doi>
  <resource>https://zenodo.org/record/3346203</resource>
  </doi_data>
  </dataset>
  </database>
  </body>
  </doi_batch>